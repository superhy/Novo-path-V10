automatically find CSV file: P62_ballooning_score_bi.csv
automatically find CSV file: P62_steatosis_score_bi.csv
automatically find CSV file: P62_lobular_inflammation_score_bi.csv
load model from: D:/FLINC_dataset/slides/yang_p62\models\checkpoint_GatedAttPool-g_Pool-0_ballooning_score_bi_[159]2023-10-02.pth
<-- load the tiles' attention score for 6 slides -->
originally attention tiles: 885 in slide: 23910-158_Sl003-C3-P62
fill surrounding tiles: 139 in round: 1
fill surrounding tiles: 14 in round: 2
all/k selection ratio in this slide: (4927 / 1038)
originally attention tiles: 2388 in slide: 23910-158_Sl004-C4-P62
fill surrounding tiles: 382 in round: 1
fill surrounding tiles: 72 in round: 2
all/k selection ratio in this slide: (17606 / 2842)
originally attention tiles: 805 in slide: 23910-158_Sl009-C7-P62
fill surrounding tiles: 107 in round: 1
fill surrounding tiles: 11 in round: 2
all/k selection ratio in this slide: (4271 / 923)
originally attention tiles: 757 in slide: 23910-158_Sl010-C7-P62
fill surrounding tiles: 72 in round: 1
fill surrounding tiles: 5 in round: 2
all/k selection ratio in this slide: (7571 / 834)
originally attention tiles: 395 in slide: 23910-158_Sl014-C10-P62
fill surrounding tiles: 36 in round: 1
fill surrounding tiles: 1 in round: 2
all/k selection ratio in this slide: (6602 / 432)
originally attention tiles: 333 in slide: 23910-158_Sl019-C13-P62
fill surrounding tiles: 30 in round: 1
fill surrounding tiles: 5 in round: 2
all/k selection ratio in this slide: (1666 / 368)
> filter the negative attention for checkpoint_GatedAttPool-g_Pool-0_steatosis_score_bi_[67]2023-11-08.pth...
load model from: D:/FLINC_dataset/slides/yang_p62\models\checkpoint_GatedAttPool-g_Pool-0_steatosis_score_bi_[67]2023-11-08.pth
<-- load the tiles' attention score for 6 slides -->
originally attention tiles: 492 in slide: 23910-158_Sl003-C3-P62
fill surrounding tiles: 58 in round: 1
fill surrounding tiles: 7 in round: 2
all/k selection ratio in this slide: (4927 / 557)
originally attention tiles: 1760 in slide: 23910-158_Sl004-C4-P62
fill surrounding tiles: 188 in round: 1
fill surrounding tiles: 24 in round: 2
all/k selection ratio in this slide: (17606 / 1972)
originally attention tiles: 427 in slide: 23910-158_Sl009-C7-P62
fill surrounding tiles: 26 in round: 1
fill surrounding tiles: 2 in round: 2
all/k selection ratio in this slide: (4271 / 455)
originally attention tiles: 757 in slide: 23910-158_Sl010-C7-P62
fill surrounding tiles: 61 in round: 1
fill surrounding tiles: 11 in round: 2
all/k selection ratio in this slide: (7571 / 829)
originally attention tiles: 660 in slide: 23910-158_Sl014-C10-P62
fill surrounding tiles: 73 in round: 1
fill surrounding tiles: 5 in round: 2
all/k selection ratio in this slide: (6602 / 738)
originally attention tiles: 166 in slide: 23910-158_Sl019-C13-P62
fill surrounding tiles: 2 in round: 1
fill surrounding tiles: 0 in round: 2
all/k selection ratio in this slide: (1666 / 168)
using negative attention, filtered/left:         486/552 for slide: 23910-158_Sl003-C3-P62
using negative attention, filtered/left:         1658/1184 for slide: 23910-158_Sl004-C4-P62
using negative attention, filtered/left:         427/496 for slide: 23910-158_Sl009-C7-P62
using negative attention, filtered/left:         607/227 for slide: 23910-158_Sl010-C7-P62
using negative attention, filtered/left:         346/86 for slide: 23910-158_Sl014-C10-P62
using negative attention, filtered/left:         147/221 for slide: 23910-158_Sl019-C13-P62
> filter the negative attention for checkpoint_GatedAttPool-g_Pool-0_lobular_inflammation_score_bi_[159]2023-11-08.pth...
load model from: D:/FLINC_dataset/slides/yang_p62\models\checkpoint_GatedAttPool-g_Pool-0_lobular_inflammation_score_bi_[159]2023-11-08.pth
<-- load the tiles' attention score for 6 slides -->
originally attention tiles: 492 in slide: 23910-158_Sl003-C3-P62
fill surrounding tiles: 46 in round: 1
fill surrounding tiles: 7 in round: 2
all/k selection ratio in this slide: (4927 / 545)
originally attention tiles: 1760 in slide: 23910-158_Sl004-C4-P62
fill surrounding tiles: 181 in round: 1
fill surrounding tiles: 28 in round: 2
all/k selection ratio in this slide: (17606 / 1969)
originally attention tiles: 427 in slide: 23910-158_Sl009-C7-P62
fill surrounding tiles: 24 in round: 1
fill surrounding tiles: 2 in round: 2
all/k selection ratio in this slide: (4271 / 453)
originally attention tiles: 757 in slide: 23910-158_Sl010-C7-P62
fill surrounding tiles: 54 in round: 1
fill surrounding tiles: 6 in round: 2
all/k selection ratio in this slide: (7571 / 817)
originally attention tiles: 660 in slide: 23910-158_Sl014-C10-P62
fill surrounding tiles: 48 in round: 1
fill surrounding tiles: 6 in round: 2
all/k selection ratio in this slide: (6602 / 714)
originally attention tiles: 166 in slide: 23910-158_Sl019-C13-P62
fill surrounding tiles: 3 in round: 1
fill surrounding tiles: 0 in round: 2
all/k selection ratio in this slide: (1666 / 169)
using negative attention, filtered/left:         79/473 for slide: 23910-158_Sl003-C3-P62
using negative attention, filtered/left:         188/996 for slide: 23910-158_Sl004-C4-P62
using negative attention, filtered/left:         57/439 for slide: 23910-158_Sl009-C7-P62
using negative attention, filtered/left:         46/181 for slide: 23910-158_Sl010-C7-P62
using negative attention, filtered/left:         12/74 for slide: 23910-158_Sl014-C10-P62
using negative attention, filtered/left:         26/195 for slide: 23910-158_Sl019-C13-P62
final highlighted tiles:  473
generate attention score heatmap (both hard and soft) for slide: 23910-158_Sl003-C3-P62
--- cut left, only keep right part!
added topK attention map numpy info set for slide: 23910-158_Sl003-C3-P62
final highlighted tiles:  996
generate attention score heatmap (both hard and soft) for slide: 23910-158_Sl004-C4-P62
--- cut left, only keep right part!
added topK attention map numpy info set for slide: 23910-158_Sl004-C4-P62
final highlighted tiles:  439
generate attention score heatmap (both hard and soft) for slide: 23910-158_Sl009-C7-P62
--- cut left, only keep right part!
added topK attention map numpy info set for slide: 23910-158_Sl009-C7-P62
final highlighted tiles:  181
generate attention score heatmap (both hard and soft) for slide: 23910-158_Sl010-C7-P62
--- cut left, only keep right part!
added topK attention map numpy info set for slide: 23910-158_Sl010-C7-P62
final highlighted tiles:  74
generate attention score heatmap (both hard and soft) for slide: 23910-158_Sl014-C10-P62
--- cut left, only keep right part!
added topK attention map numpy info set for slide: 23910-158_Sl014-C10-P62
final highlighted tiles:  195
generate attention score heatmap (both hard and soft) for slide: 23910-158_Sl019-C13-P62
--- cut left, only keep right part!
added topK attention map numpy info set for slide: 23910-158_Sl019-C13-P62
Store topK attention map numpy package as: topK_map_GatedAttPool-g_Pool-0_ballooning_score_bi_[159]2023-10-02.pkl
